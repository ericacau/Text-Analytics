{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing & utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# text handling \n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# models for classification\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(pipeline, X_test, y_test):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plot_confusion_matrix(pipeline, X_test, y_test)  \n",
    "    plt.xticks(rotation=45, fontsize = 10)\n",
    "    plt.yticks(rotation=0, fontsize = 8)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "def eval_accuracy (pred, test):\n",
    "    correct = 0\n",
    "    for prediction,true_label in zip(predictions, y_test):\n",
    "        if prediction==true_label:\n",
    "            correct += 1\n",
    "    return (correct/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/books_def.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36638 entries, Suzanne Collins to Mimi Baird|Eve Claxton\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   book_desc    36638 non-null  object \n",
      " 1   book_rating  36638 non-null  float64\n",
      " 2   book_title   36638 non-null  object \n",
      " 3   genres       36638 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_authors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Suzanne Collins</th>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J.K. Rowling|Mary GrandPré</th>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>4.48</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harper Lee</th>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>4.27</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephenie Meyer</th>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>3.58</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markus Zusak</th>\n",
       "      <td>Trying to make sense of the horrors of World W...</td>\n",
       "      <td>4.36</td>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>Historical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    book_desc  \\\n",
       "book_authors                                                                    \n",
       "Suzanne Collins             Winning will make you famous. Losing means cer...   \n",
       "J.K. Rowling|Mary GrandPré  There is a door at the end of a silent corrido...   \n",
       "Harper Lee                  The unforgettable novel of a childhood in a sl...   \n",
       "Stephenie Meyer             About three things I was absolutely positive.F...   \n",
       "Markus Zusak                Trying to make sense of the horrors of World W...   \n",
       "\n",
       "                            book_rating  \\\n",
       "book_authors                              \n",
       "Suzanne Collins                    4.33   \n",
       "J.K. Rowling|Mary GrandPré         4.48   \n",
       "Harper Lee                         4.27   \n",
       "Stephenie Meyer                    3.58   \n",
       "Markus Zusak                       4.36   \n",
       "\n",
       "                                                           book_title  \\\n",
       "book_authors                                                            \n",
       "Suzanne Collins                                      The Hunger Games   \n",
       "J.K. Rowling|Mary GrandPré  Harry Potter and the Order of the Phoenix   \n",
       "Harper Lee                                      To Kill a Mockingbird   \n",
       "Stephenie Meyer                                              Twilight   \n",
       "Markus Zusak                                           The Book Thief   \n",
       "\n",
       "                                 genres  \n",
       "book_authors                             \n",
       "Suzanne Collins             Young Adult  \n",
       "J.K. Rowling|Mary GrandPré      Fantasy  \n",
       "Harper Lee                     Classics  \n",
       "Stephenie Meyer             Young Adult  \n",
       "Markus Zusak                 Historical  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Winning will make you famous. Losing means cer...\n",
       "1        There is a door at the end of a silent corrido...\n",
       "2        The unforgettable novel of a childhood in a sl...\n",
       "3        About three things I was absolutely positive.F...\n",
       "4        Trying to make sense of the horrors of World W...\n",
       "                               ...                        \n",
       "36633    A brilliant, provocative novel about an artist...\n",
       "36634    Avi Steinberg is stumped. After defecting from...\n",
       "36635    In this fearless and half-crazy story, Howard ...\n",
       "36636    From the icons of the game to the players who ...\n",
       "36637    Soon to be a major motion picture, from Brad P...\n",
       "Name: book_desc, Length: 36638, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"book_desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggo testi & etichette\n",
    "X = df[\"book_desc\"]\n",
    "y = df[\"genres\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Winner of the 2007 BookBrowse Award for Most Popular Book.An atmospheric, gritty, and compelling novel of star-crossed lovers, set in the circus world circa 1932, by the bestselling author of Riding Lessons. When Jacob Jankowski, recently orphaned and suddenly adrift, jumps onto a passing train, he enters a world of freaks, drifters, and misfits, a second-rate circus struggling to survive during the Great Depression, making one-night stands in town after endless town. A veterinary student who almost earned his degree, Jacob is put in charge of caring for the circus menagerie. It is there that he meets Marlena, the beautiful young star of the equestrian act, who is married to August, the charismatic but twisted animal trainer. He also meets Rosie, an elephant who seems untrainable until he discovers a way to reach her. Beautifully written, Water for Elephants is illuminated by a wonderful sense of time and place. It tells a story of a love between two people that overcomes incredible odds in a world in which even love is a luxury that few can afford.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 50\n",
    "X_train[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fiction'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[sample_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def spacy_nlp_tokenizer(text):\n",
    "    # substituting all space characters with a single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub('\\r+', ' ', text)\n",
    "    # removing Url\n",
    "    text = re.sub(r\"\\S*https?:\\S*\", \"\", text, flags=re.MULTILINE)\n",
    "    #removing mention\n",
    "    text = re.sub(r'@[\\w]+', \"\", text, flags=re.MULTILINE)\n",
    "    doc = nlp(text)\n",
    "    # lemmatizing tokens and lowering case\n",
    "    lemmas = [token.lemma_.lower() for token in doc]\n",
    "    \n",
    "    # removing stopwords and punctuations\n",
    "    lemmas_nostop = [token for token in lemmas if token not in stopword_list and token not in punctuations]\n",
    "\n",
    "    # creating ngrams\n",
    "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas_nostop,2)]\n",
    "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas_nostop,3)]\n",
    "    \n",
    "    all_tokens = list()\n",
    "    all_tokens.extend(lemmas_nostop)\n",
    "    all_tokens.extend(lemma_bigrams)\n",
    "    all_tokens.extend(lemma_trigrams)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickle/svm_train_tok.pkl',mode='br') as inputfile:\n",
    "    X_train_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/svm_test_tok.pkl',mode='br') as inputfile:\n",
    "    X_test_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/vect.pkl',mode='br') as inputfile:\n",
    "    vect = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  25646 Genres:  25646\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \", len(X_train), \"Genres: \", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  10992 Genres:  10992\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \", len(X_test), \"Genres: \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fiction', 'Fantasy', 'Nonfiction', 'Romance', 'Science Fiction', 'Historical', 'Mystery', 'Classics', 'Sequential Art', 'Young Adult'} \n",
      " {'Fiction', 'Romance', 'Nonfiction', 'Fantasy', 'Science Fiction', 'Historical', 'Mystery', 'Classics', 'Sequential Art', 'Young Adult'}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_test), \"\\n\", set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=1000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', DecisionTreeClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = dt_pipeline.predict(X_test_tok)\n",
    "predictions_train = dt_pipeline.predict(X_train_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3913755458515284"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report training :\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.99      1.00      0.99      1111\n",
      "        Fantasy       1.00      1.00      1.00      4412\n",
      "        Fiction       1.00      1.00      1.00      4980\n",
      "     Historical       1.00      1.00      1.00      1501\n",
      "        Mystery       1.00      1.00      1.00      1429\n",
      "     Nonfiction       1.00      1.00      1.00      4553\n",
      "        Romance       1.00      1.00      1.00      3177\n",
      "Science Fiction       1.00      1.00      1.00      1225\n",
      " Sequential Art       1.00      1.00      1.00       931\n",
      "    Young Adult       1.00      1.00      1.00      2327\n",
      "\n",
      "       accuracy                           1.00     25646\n",
      "      macro avg       1.00      1.00      1.00     25646\n",
      "   weighted avg       1.00      1.00      1.00     25646\n",
      "\n",
      "Confusion matrix training :\n",
      "[[1109    0    0    1    0    1    0    0    0    0]\n",
      " [   2 4404    0    1    0    5    0    0    0    0]\n",
      " [   6    1 4964    1    0    7    1    0    0    0]\n",
      " [   0    1    1 1497    0    2    0    0    0    0]\n",
      " [   1    0    0    1 1426    1    0    0    0    0]\n",
      " [   6    2    0    3    0 4542    0    0    0    0]\n",
      " [   0    0    0    0    0    1 3176    0    0    0]\n",
      " [   0    3    1    0    0    1    0 1220    0    0]\n",
      " [   0    0    0    0    0    3    0    0  928    0]\n",
      " [   0    1    0    0    0    1    1    0    0 2324]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification report training :')\n",
    "print(classification_report(y_train, predictions_train))\n",
    "\n",
    "print('Confusion matrix training :')\n",
    "cm = confusion_matrix(y_train, predictions_train)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.28      0.25      0.27       477\n",
      "        Fantasy       0.42      0.43      0.43      1891\n",
      "        Fiction       0.35      0.37      0.36      2134\n",
      "     Historical       0.21      0.20      0.20       643\n",
      "        Mystery       0.32      0.27      0.29       612\n",
      "     Nonfiction       0.57      0.63      0.60      1951\n",
      "        Romance       0.41      0.40      0.40      1362\n",
      "Science Fiction       0.31      0.27      0.29       525\n",
      " Sequential Art       0.28      0.23      0.26       399\n",
      "    Young Adult       0.28      0.28      0.28       998\n",
      "\n",
      "       accuracy                           0.39     10992\n",
      "      macro avg       0.34      0.33      0.34     10992\n",
      "   weighted avg       0.39      0.39      0.39     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 121   39  121   24   10  102   22   13   13   12]\n",
      " [  46  813  266   73   67  153  207   66   51  149]\n",
      " [  84  263  796  136   84  297  199   71   42  162]\n",
      " [  20   84  166  126   31   75   50   20   15   56]\n",
      " [  18   83  129   36  167   47   51   12   17   52]\n",
      " [  79  105  259   61   29 1229   68   39   36   46]\n",
      " [  17  208  183   77   52   75  539   39   15  157]\n",
      " [  15   89   80   20   29   52   35  141   16   48]\n",
      " [   8   68   71   13   21   56   21   22   93   26]\n",
      " [  21  174  185   38   37   68  132   36   30  277]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df = 5)), #tokenization\n",
    "    ('sel', SelectKBest(chi2, k=\"all\")),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', DecisionTreeClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train,y_train)\n",
    "predictions_train = dt_pipeline.predict(X_train)\n",
    "predictions = dt_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36872270742358076"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report training :\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.99      1.00      0.99      1111\n",
      "        Fantasy       1.00      1.00      1.00      4412\n",
      "        Fiction       1.00      1.00      1.00      4980\n",
      "     Historical       0.99      1.00      1.00      1501\n",
      "        Mystery       1.00      1.00      1.00      1429\n",
      "     Nonfiction       1.00      1.00      1.00      4553\n",
      "        Romance       1.00      1.00      1.00      3177\n",
      "Science Fiction       1.00      1.00      1.00      1225\n",
      " Sequential Art       1.00      1.00      1.00       931\n",
      "    Young Adult       1.00      1.00      1.00      2327\n",
      "\n",
      "       accuracy                           1.00     25646\n",
      "      macro avg       1.00      1.00      1.00     25646\n",
      "   weighted avg       1.00      1.00      1.00     25646\n",
      "\n",
      "Confusion matrix training :\n",
      "[[1110    0    0    1    0    0    0    0    0    0]\n",
      " [   2 4409    0    1    0    0    0    0    0    0]\n",
      " [   6    1 4972    1    0    0    0    0    0    0]\n",
      " [   0    0    0 1501    0    0    0    0    0    0]\n",
      " [   1    0    0    1 1427    0    0    0    0    0]\n",
      " [   5    0    1    4    0 4543    0    0    0    0]\n",
      " [   0    0    0    0    0    0 3177    0    0    0]\n",
      " [   0    0    0    0    0    0    0 1225    0    0]\n",
      " [   0    0    0    0    0    0    0    0  931    0]\n",
      " [   0    1    0    0    0    0    1    0    0 2325]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification report training :')\n",
    "print(classification_report(y_train, predictions_train))\n",
    "\n",
    "print('Confusion matrix training :')\n",
    "cm = confusion_matrix(y_train, predictions_train)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.25      0.25      0.25       477\n",
      "        Fantasy       0.39      0.39      0.39      1891\n",
      "        Fiction       0.35      0.37      0.36      2134\n",
      "     Historical       0.16      0.15      0.16       643\n",
      "        Mystery       0.26      0.24      0.25       612\n",
      "     Nonfiction       0.56      0.59      0.58      1951\n",
      "        Romance       0.41      0.39      0.40      1362\n",
      "Science Fiction       0.24      0.25      0.24       525\n",
      " Sequential Art       0.24      0.22      0.23       399\n",
      "    Young Adult       0.26      0.25      0.25       998\n",
      "\n",
      "       accuracy                           0.37     10992\n",
      "      macro avg       0.31      0.31      0.31     10992\n",
      "   weighted avg       0.36      0.37      0.37     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 118   41  117   23   18   96   15   15   15   19]\n",
      " [  53  746  305   84   80  166  165   87   49  156]\n",
      " [ 111  260  785  140   89  271  178   97   55  148]\n",
      " [  28   95  159   98   24   79   68   28   18   46]\n",
      " [   9   94  109   36  144   53   75   21   14   57]\n",
      " [  75  132  294   60   32 1160   49   52   45   52]\n",
      " [  32  197  172   73   72   77  537   34   24  144]\n",
      " [  14   82   84   24   24   51   40  129   25   52]\n",
      " [  11   64   80   13   18   50   21   28   88   26]\n",
      " [  16  180  158   48   55   67  146   45   35  248]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = vect\n",
    "selector = dt_pipeline.named_steps['sel']\n",
    "classifier = dt_pipeline.named_steps['learner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9a45b35e2748>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeats_w_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfeats_w_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselected\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfeats_w_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats_w_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats_w_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "feature_names = tokenizer.get_feature_names()\n",
    "feats_w_score = list()\n",
    "for index,(selected,score) in enumerate(zip(selector.get_support(),selector.scores_)):\n",
    "    feats_w_score.append((score,selected,feature_names[index]))\n",
    "feats_w_score = sorted(feats_w_score)\n",
    "len(feats_w_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w_score[-100:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w_score[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_nonfic = ['Fiction', 'Nonfiction']\n",
    "df_binary = df.loc[df['genres'].isin(fic_nonfic)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = df_binary[\"book_desc\"]\n",
    "y_binary = df_binary[\"genres\"]\n",
    "\n",
    "\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_binary, y_binary,  test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect= TfidfVectorizer(max_df=0.8, max_features=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "transform\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('fit')\n",
    "# Just creating the features space. It define the dimensions.\n",
    "vect.fit(X_train_binary) \n",
    "print('transform')\n",
    "#Creating the vectors\n",
    "X_train_tok_binary = vect.transform(X_train_binary)\n",
    "print('done')\n",
    "X_test_tok_binary = vect.transform(X_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fiction       1.00      1.00      1.00      4990\n",
      "  Nonfiction       1.00      1.00      1.00      4542\n",
      "\n",
      "    accuracy                           1.00      9532\n",
      "   macro avg       1.00      1.00      1.00      9532\n",
      "weighted avg       1.00      1.00      1.00      9532\n",
      "\n",
      "Confusion matrix:\n",
      "[[4988    2]\n",
      " [   2 4540]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df = 5)), #tokenization\n",
    "    ('sel', SelectKBest(chi2, k=7000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_binary, y_train_binary)\n",
    "predictions_test_binary = RF_pipeline.predict(X_test_binary)\n",
    "predictions_train_binary = RF_pipeline.predict(X_train_binary)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_train_binary, predictions_train_binary))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_train_binary, predictions_train_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fiction       0.85      0.92      0.88      2124\n",
      "  Nonfiction       0.90      0.82      0.86      1962\n",
      "\n",
      "    accuracy                           0.87      4086\n",
      "   macro avg       0.88      0.87      0.87      4086\n",
      "weighted avg       0.88      0.87      0.87      4086\n",
      "\n",
      "Confusion matrix:\n",
      "[[1952  172]\n",
      " [ 348 1614]]\n"
     ]
    }
   ],
   "source": [
    "predictions_test_binary = RF_pipeline.predict(X_test_binary)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test_binary, predictions_test_binary))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test_binary, predictions_test_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

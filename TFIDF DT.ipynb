{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing & utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# text handling \n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# models for classification\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(pipeline, X_test, y_test):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plot_confusion_matrix(pipeline, X_test, y_test)  \n",
    "    plt.xticks(rotation=45, fontsize = 10)\n",
    "    plt.yticks(rotation=0, fontsize = 8)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "def eval_accuracy (pred, test):\n",
    "    correct = 0\n",
    "    for prediction,true_label in zip(predictions, y_test):\n",
    "        if prediction==true_label:\n",
    "            correct += 1\n",
    "    return (correct/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/books_def.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36638 entries, Suzanne Collins to Mimi Baird|Eve Claxton\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   book_desc    36638 non-null  object \n",
      " 1   book_rating  36638 non-null  float64\n",
      " 2   book_title   36638 non-null  object \n",
      " 3   genres       36638 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling|Mary GrandPré</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>4.48</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>4.27</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>3.58</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Markus Zusak</td>\n",
       "      <td>Trying to make sense of the horrors of World W...</td>\n",
       "      <td>4.36</td>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>Historical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 book_authors  \\\n",
       "0             Suzanne Collins   \n",
       "1  J.K. Rowling|Mary GrandPré   \n",
       "2                  Harper Lee   \n",
       "3             Stephenie Meyer   \n",
       "4                Markus Zusak   \n",
       "\n",
       "                                           book_desc  book_rating  \\\n",
       "0  Winning will make you famous. Losing means cer...         4.33   \n",
       "1  There is a door at the end of a silent corrido...         4.48   \n",
       "2  The unforgettable novel of a childhood in a sl...         4.27   \n",
       "3  About three things I was absolutely positive.F...         3.58   \n",
       "4  Trying to make sense of the horrors of World W...         4.36   \n",
       "\n",
       "                                  book_title       genres  \n",
       "0                           The Hunger Games  Young Adult  \n",
       "1  Harry Potter and the Order of the Phoenix      Fantasy  \n",
       "2                      To Kill a Mockingbird     Classics  \n",
       "3                                   Twilight  Young Adult  \n",
       "4                             The Book Thief   Historical  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Winning will make you famous. Losing means cer...\n",
       "1        There is a door at the end of a silent corrido...\n",
       "2        The unforgettable novel of a childhood in a sl...\n",
       "3        About three things I was absolutely positive.F...\n",
       "4        Trying to make sense of the horrors of World W...\n",
       "                               ...                        \n",
       "36633    A brilliant, provocative novel about an artist...\n",
       "36634    Avi Steinberg is stumped. After defecting from...\n",
       "36635    In this fearless and half-crazy story, Howard ...\n",
       "36636    From the icons of the game to the players who ...\n",
       "36637    Soon to be a major motion picture, from Brad P...\n",
       "Name: book_desc, Length: 36638, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"book_desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggo testi & etichette\n",
    "X = df[\"book_desc\"]\n",
    "y = df[\"genres\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Winner of the 2007 BookBrowse Award for Most Popular Book.An atmospheric, gritty, and compelling novel of star-crossed lovers, set in the circus world circa 1932, by the bestselling author of Riding Lessons. When Jacob Jankowski, recently orphaned and suddenly adrift, jumps onto a passing train, he enters a world of freaks, drifters, and misfits, a second-rate circus struggling to survive during the Great Depression, making one-night stands in town after endless town. A veterinary student who almost earned his degree, Jacob is put in charge of caring for the circus menagerie. It is there that he meets Marlena, the beautiful young star of the equestrian act, who is married to August, the charismatic but twisted animal trainer. He also meets Rosie, an elephant who seems untrainable until he discovers a way to reach her. Beautifully written, Water for Elephants is illuminated by a wonderful sense of time and place. It tells a story of a love between two people that overcomes incredible odds in a world in which even love is a luxury that few can afford.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 50\n",
    "X_train[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fiction'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[sample_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def spacy_nlp_tokenizer(text):\n",
    "    # substituting all space characters with a single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub('\\r+', ' ', text)\n",
    "    # removing Url\n",
    "    text = re.sub(r\"\\S*https?:\\S*\", \"\", text, flags=re.MULTILINE)\n",
    "    #removing mention\n",
    "    text = re.sub(r'@[\\w]+', \"\", text, flags=re.MULTILINE)\n",
    "    doc = nlp(text)\n",
    "    # lemmatizing tokens and lowering case\n",
    "    lemmas = [token.lemma_.lower() for token in doc]\n",
    "    \n",
    "    # removing stopwords and punctuations\n",
    "    lemmas_nostop = [token for token in lemmas if token not in stopword_list and token not in punctuations]\n",
    "\n",
    "    # creating ngrams\n",
    "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas_nostop,2)]\n",
    "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas_nostop,3)]\n",
    "    \n",
    "    all_tokens = list()\n",
    "    all_tokens.extend(lemmas_nostop)\n",
    "    all_tokens.extend(lemma_bigrams)\n",
    "    all_tokens.extend(lemma_trigrams)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickle/svm_train_tok.pkl',mode='br') as inputfile:\n",
    "    X_train_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/svm_test_tok.pkl',mode='br') as inputfile:\n",
    "    X_test_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/vect.pkl',mode='br') as inputfile:\n",
    "    vect = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  25646 Genres:  25646\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \", len(X_train), \"Genres: \", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  10992 Genres:  10992\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \", len(X_test), \"Genres: \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Historical', 'Nonfiction', 'Science Fiction', 'Fiction', 'Sequential Art', 'Fantasy', 'Mystery', 'Young Adult', 'Romance', 'Classics'} \n",
      " {'Historical', 'Nonfiction', 'Science Fiction', 'Fiction', 'Sequential Art', 'Fantasy', 'Mystery', 'Young Adult', 'Romance', 'Classics'}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_test), \"\\n\", set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69255"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.27      0.28      0.28       477\n",
      "        Fantasy       0.44      0.44      0.44      1891\n",
      "        Fiction       0.35      0.38      0.37      2134\n",
      "     Historical       0.22      0.19      0.20       643\n",
      "        Mystery       0.33      0.34      0.34       612\n",
      "     Nonfiction       0.56      0.57      0.56      1951\n",
      "        Romance       0.38      0.40      0.39      1362\n",
      "Science Fiction       0.37      0.32      0.35       525\n",
      " Sequential Art       0.37      0.32      0.34       399\n",
      "    Young Adult       0.26      0.25      0.26       998\n",
      "\n",
      "       accuracy                           0.39     10992\n",
      "      macro avg       0.36      0.35      0.35     10992\n",
      "   weighted avg       0.39      0.39      0.39     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 134   41  124   31   17   84   14    6    6   20]\n",
      " [  41  835  247   73   62  149  198   68   55  163]\n",
      " [ 122  228  809  113   94  267  225   65   22  189]\n",
      " [  35   84  171  122   29   67   65   17   17   36]\n",
      " [  18   77  109   27  209   46   53   14   18   41]\n",
      " [  78  133  305   64   41 1104   89   42   35   60]\n",
      " [  23  181  201   74   63   87  538   29   20  146]\n",
      " [  14   86   76   18   26   45   41  170   19   30]\n",
      " [  15   54   40   13   30   50   25   16  128   28]\n",
      " [  16  166  203   22   58   64  160   29   26  254]]\n"
     ]
    }
   ],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=1000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', DecisionTreeClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = dt_pipeline.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3914665211062591"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.27      0.23      0.25       477\n",
      "        Fantasy       0.39      0.42      0.40      1891\n",
      "        Fiction       0.37      0.38      0.37      2134\n",
      "     Historical       0.19      0.17      0.18       643\n",
      "        Mystery       0.26      0.22      0.24       612\n",
      "     Nonfiction       0.56      0.59      0.58      1951\n",
      "        Romance       0.41      0.42      0.42      1362\n",
      "Science Fiction       0.23      0.22      0.23       525\n",
      " Sequential Art       0.27      0.22      0.24       399\n",
      "    Young Adult       0.28      0.27      0.27       998\n",
      "\n",
      "       accuracy                           0.38     10992\n",
      "      macro avg       0.32      0.31      0.32     10992\n",
      "   weighted avg       0.37      0.38      0.37     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 110   51  119   34   10   92   26   12    6   17]\n",
      " [  46  787  271   74   66  164  192   72   54  165]\n",
      " [  77  276  818  133   79  282  170   95   46  158]\n",
      " [  21  111  144  107   29   83   63   25   17   43]\n",
      " [  17   78  123   34  132   47   72   32   18   59]\n",
      " [  71  144  276   55   52 1156   61   52   31   53]\n",
      " [  21  212  161   66   55   60  570   48   23  146]\n",
      " [  10   92  100   18   21   55   48  118   20   43]\n",
      " [  13   72   72   16   16   50   21   31   86   22]\n",
      " [  23  197  157   37   46   59  160   29   20  270]]\n"
     ]
    }
   ],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df = 5)), #tokenization\n",
    "    ('sel', SelectKBest(chi2, k=7000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', DecisionTreeClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train,y_train)\n",
    "predictions = dt_pipeline.predict(X_test)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37791120815138285"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

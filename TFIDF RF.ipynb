{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing & visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models for classification\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(pipeline, X_test, y_test):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plot_confusion_matrix(pipeline, X_test, y_test)  \n",
    "    plt.xticks(rotation=45, fontsize = 10)\n",
    "    plt.yticks(rotation=0, fontsize = 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/books_def.csv\", index_col=0)\n",
    "fic_nonfic = ['Fiction', 'Nonfiction']\n",
    "df_binary = df.loc[df['genres'].isin(fic_nonfic)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggo testi & etichette\n",
    "X = df[\"book_desc\"]\n",
    "y = df[\"genres\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickle/svm_train_tok.pkl',mode='br') as inputfile:\n",
    "    X_train_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/svm_test_tok.pkl',mode='br') as inputfile:\n",
    "    X_test_tok = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.80      0.13      0.22       477\n",
      "        Fantasy       0.54      0.71      0.61      1891\n",
      "        Fiction       0.43      0.63      0.51      2134\n",
      "     Historical       0.87      0.05      0.10       643\n",
      "        Mystery       0.70      0.31      0.43       612\n",
      "     Nonfiction       0.65      0.88      0.74      1951\n",
      "        Romance       0.57      0.68      0.62      1362\n",
      "Science Fiction       0.73      0.24      0.36       525\n",
      " Sequential Art       0.90      0.13      0.23       399\n",
      "    Young Adult       0.57      0.28      0.38       998\n",
      "\n",
      "       accuracy                           0.55     10992\n",
      "      macro avg       0.68      0.40      0.42     10992\n",
      "   weighted avg       0.61      0.55      0.51     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[  61   35  201    0    3  167    5    1    0    4]\n",
      " [   2 1337  214    1   13  101  161   10    3   49]\n",
      " [   8  225 1343    3   26  305  156   14    1   53]\n",
      " [   1  118  312   34    6   85   71    2    0   14]\n",
      " [   0   95  199    0  189   42   65    0    1   21]\n",
      " [   4   16  192    0    2 1708   20    4    0    5]\n",
      " [   0  147  180    1   12   43  931    2    0   46]\n",
      " [   0  150  134    0    8   60   37  127    1    8]\n",
      " [   0   93  130    0    2   81   14   13   52   14]\n",
      " [   0  257  219    0   10   49  177    2    0  284]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=5000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = RF_pipeline.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=5)]: Done  90 out of  90 | elapsed: 43.7min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'sel__k': [3000, 5000, 7000],'learner__criterion': [\"entropy\", \"gini\"], 'learner__n_estimators': [100, 300, 500]}]\n",
    "\n",
    "opt_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier(bootstrap = True))  # learning algorithm\n",
    "])\n",
    "\n",
    "n_jobs = 5  #Number of jobs to run in parallel\n",
    "opt_search = GridSearchCV(opt_pipeline, param_grid, cv=5, n_jobs = n_jobs, verbose=True).fit(X_train_tok,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner__criterion': 'gini', 'learner__n_estimators': 500, 'sel__k': 3000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k=3000,\n",
       "                             score_func=<function chi2 at 0x000001869C257F70>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner', RandomForestClassifier(n_estimators=500))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.80      0.15      0.25       477\n",
      "        Fantasy       0.56      0.70      0.62      1891\n",
      "        Fiction       0.44      0.64      0.52      2134\n",
      "     Historical       0.89      0.06      0.12       643\n",
      "        Mystery       0.72      0.37      0.49       612\n",
      "     Nonfiction       0.65      0.87      0.74      1951\n",
      "        Romance       0.58      0.70      0.63      1362\n",
      "Science Fiction       0.72      0.30      0.43       525\n",
      " Sequential Art       0.90      0.18      0.30       399\n",
      "    Young Adult       0.57      0.30      0.40       998\n",
      "\n",
      "       accuracy                           0.56     10992\n",
      "      macro avg       0.68      0.43      0.45     10992\n",
      "   weighted avg       0.61      0.56      0.53     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[  72   25  208    0    5  152    8    3    0    4]\n",
      " [   4 1326  230    1   15  103  147   13    4   48]\n",
      " [   8  201 1356    2   26  299  167   20    1   54]\n",
      " [   0  108  312   41    4   87   70    2    0   19]\n",
      " [   1   95  182    0  226   28   58    0    1   21]\n",
      " [   4   24  199    0    1 1691   23    3    1    5]\n",
      " [   1  128  168    2   15   42  953    3    0   50]\n",
      " [   0  118  117    0    8   66   45  159    1   11]\n",
      " [   0   94  105    0    7   76   11   16   71   19]\n",
      " [   0  258  209    0    6   48  170    3    0  304]]\n"
     ]
    }
   ],
   "source": [
    "opt_predictions = opt_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, opt_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.78      0.10      0.18       477\n",
      "        Fantasy       0.56      0.71      0.63      1891\n",
      "        Fiction       0.42      0.65      0.51      2134\n",
      "     Historical       1.00      0.02      0.05       643\n",
      "        Mystery       0.75      0.30      0.42       612\n",
      "     Nonfiction       0.65      0.89      0.75      1951\n",
      "        Romance       0.58      0.71      0.64      1362\n",
      "Science Fiction       0.77      0.24      0.37       525\n",
      " Sequential Art       0.93      0.13      0.23       399\n",
      "    Young Adult       0.61      0.26      0.37       998\n",
      "\n",
      "       accuracy                           0.56     10992\n",
      "      macro avg       0.71      0.40      0.42     10992\n",
      "   weighted avg       0.63      0.56      0.51     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[  50   28  218    0    3  166    7    1    0    4]\n",
      " [   3 1347  230    0   11  112  144    7    2   35]\n",
      " [   7  204 1390    0   19  305  156   11    0   42]\n",
      " [   1  109  349   15    4   82   66    2    0   15]\n",
      " [   0   85  228    0  181   34   65    0    0   19]\n",
      " [   2   14  177    0    0 1729   23    3    0    3]\n",
      " [   1  134  176    0    9   44  966    2    0   30]\n",
      " [   0  135  144    0    5   69   33  128    2    9]\n",
      " [   0   98  127    0    4   81   11   10   53   15]\n",
      " [   0  257  238    0    5   48  184    2    0  264]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=7000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier(n_estimators=500, criterion = \"gini\"))  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = RF_pipeline.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = df_binary[\"book_desc\"]\n",
    "y_binary = df_binary[\"genres\"]\n",
    "\n",
    "\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_binary, y_binary,  test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect= TfidfVectorizer(max_df=0.8, max_features=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "transform\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('fit')\n",
    "# Just creating the features space. It define the dimensions.\n",
    "vect.fit(X_train_binary) \n",
    "print('transform')\n",
    "#Creating the vectors\n",
    "X_train_tok_binary = vect.transform(X_train_binary)\n",
    "print('done')\n",
    "X_test_tok_binary = vect.transform(X_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fiction       1.00      1.00      1.00      4990\n",
      "  Nonfiction       1.00      1.00      1.00      4542\n",
      "\n",
      "    accuracy                           1.00      9532\n",
      "   macro avg       1.00      1.00      1.00      9532\n",
      "weighted avg       1.00      1.00      1.00      9532\n",
      "\n",
      "Confusion matrix:\n",
      "[[4989    1]\n",
      " [   3 4539]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df = 5)), #tokenization\n",
    "    ('sel', SelectKBest(chi2, k=7000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_binary, y_train_binary)\n",
    "predictions_test_binary = RF_pipeline.predict(X_test_binary)\n",
    "predictions_train_binary = RF_pipeline.predict(X_train_binary)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_train_binary, predictions_train_binary))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_train_binary, predictions_train_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fiction       0.85      0.92      0.88      2124\n",
      "  Nonfiction       0.90      0.82      0.86      1962\n",
      "\n",
      "    accuracy                           0.87      4086\n",
      "   macro avg       0.88      0.87      0.87      4086\n",
      "weighted avg       0.87      0.87      0.87      4086\n",
      "\n",
      "Confusion matrix:\n",
      "[[1945  179]\n",
      " [ 344 1618]]\n"
     ]
    }
   ],
   "source": [
    "predictions_test_binary = RF_pipeline.predict(X_test_binary)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test_binary, predictions_test_binary))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test_binary, predictions_test_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

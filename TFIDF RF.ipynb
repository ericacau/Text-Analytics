{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing & visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models for classification\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(pipeline, X_test, y_test):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plot_confusion_matrix(pipeline, X_test, y_test)  \n",
    "    plt.xticks(rotation=45, fontsize = 10)\n",
    "    plt.yticks(rotation=0, fontsize = 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/books_def_small.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggo testi & etichette\n",
    "X = df[\"book_desc\"]\n",
    "y = df[\"genres\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickle/svm_train_tok.pkl',mode='br') as inputfile:\n",
    "    X_train_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/svm_test_tok.pkl',mode='br') as inputfile:\n",
    "    X_test_tok = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.92      0.11      0.20       302\n",
      "        Fantasy       0.51      0.81      0.62      1693\n",
      "        Fiction       0.43      0.73      0.54      1464\n",
      "     Historical       0.69      0.09      0.16       573\n",
      "        Mystery       0.73      0.42      0.53       538\n",
      "     Nonfiction       0.79      0.52      0.63       667\n",
      "        Romance       0.59      0.66      0.62      1049\n",
      "Science Fiction       0.82      0.31      0.45       444\n",
      " Sequential Art       0.96      0.27      0.42       386\n",
      "    Young Adult       0.57      0.33      0.42       830\n",
      "\n",
      "       accuracy                           0.54      7946\n",
      "      macro avg       0.70      0.42      0.46      7946\n",
      "   weighted avg       0.62      0.54      0.51      7946\n",
      "\n",
      "Confusion matrix:\n",
      "[[  33   46  192    3    2   12   10    2    0    2]\n",
      " [   0 1366  148    4   14   17  105    5    1   33]\n",
      " [   2  198 1068    6   27   23   99    4    1   36]\n",
      " [   0  159  283   50    9    5   45    1    0   21]\n",
      " [   0  121  111    1  225    2   49    2    0   27]\n",
      " [   1   47  235    3    2  350   17    5    1    6]\n",
      " [   0  177  114    3   11   10  689    1    0   44]\n",
      " [   0  162   98    1    6    8   17  137    1   14]\n",
      " [   0  139   87    0    5   13    7    8  105   22]\n",
      " [   0  285  129    1    8    4  125    3    0  275]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=5000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = RF_pipeline.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=5)]: Done  90 out of  90 | elapsed: 64.5min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'sel__k': [3000, 5000, 7000],'learner__criterion': [\"entropy\", \"gini\"], 'learner__n_estimators': [100, 300, 500]}]\n",
    "\n",
    "opt_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier(bootstrap = True))  # learning algorithm\n",
    "])\n",
    "\n",
    "n_jobs = 5  #Number of jobs to run in parallel\n",
    "opt_search = GridSearchCV(opt_pipeline, param_grid, cv=5, n_jobs = n_jobs, verbose=True).fit(X_train_tok,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner__criterion': 'gini', 'learner__n_estimators': 500, 'sel__k': 5000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k=5000,\n",
       "                             score_func=<function chi2 at 0x0000022897C189D0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner', RandomForestClassifier(n_estimators=500))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.79      0.12      0.20       477\n",
      "        Fantasy       0.56      0.72      0.63      1891\n",
      "        Fiction       0.44      0.67      0.53      2134\n",
      "     Historical       0.86      0.03      0.05       643\n",
      "        Mystery       0.74      0.29      0.42       612\n",
      "     Nonfiction       0.66      0.88      0.75      1951\n",
      "        Romance       0.59      0.71      0.64      1362\n",
      "Science Fiction       0.77      0.26      0.39       525\n",
      " Sequential Art       0.92      0.14      0.25       399\n",
      "    Young Adult       0.63      0.27      0.38       998\n",
      "\n",
      "       accuracy                           0.56     10992\n",
      "      macro avg       0.69      0.41      0.42     10992\n",
      "   weighted avg       0.62      0.56      0.52     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[  55   25  215    0    3  166    8    2    0    3]\n",
      " [   2 1364  237    0   10   98  136    7    4   33]\n",
      " [   7  197 1425    3   15  286  152   12    0   37]\n",
      " [   1  116  336   18    5   78   73    2    0   14]\n",
      " [   0   97  221    0  180   35   61    0    0   18]\n",
      " [   4   16  177    0    0 1726   22    3    0    3]\n",
      " [   1  141  173    0   10   41  964    1    0   31]\n",
      " [   0  142  127    0    6   66   39  135    1    9]\n",
      " [   0   98  126    0    6   77    9   11   57   15]\n",
      " [   0  256  219    0    9   56  182    2    0  274]]\n"
     ]
    }
   ],
   "source": [
    "opt_predictions = opt_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, opt_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.97      0.12      0.21       302\n",
      "        Fantasy       0.51      0.83      0.63      1693\n",
      "        Fiction       0.45      0.76      0.57      1464\n",
      "     Historical       0.67      0.06      0.11       573\n",
      "        Mystery       0.77      0.42      0.54       538\n",
      "     Nonfiction       0.82      0.56      0.66       667\n",
      "        Romance       0.60      0.68      0.64      1049\n",
      "Science Fiction       0.82      0.28      0.42       444\n",
      " Sequential Art       0.90      0.26      0.40       386\n",
      "    Young Adult       0.59      0.34      0.43       830\n",
      "\n",
      "       accuracy                           0.55      7946\n",
      "      macro avg       0.71      0.43      0.46      7946\n",
      "   weighted avg       0.63      0.55      0.52      7946\n",
      "\n",
      "Confusion matrix:\n",
      "[[  35   43  192    3    2   12   10    2    0    3]\n",
      " [   0 1407  126    3   11   13  103    2    3   25]\n",
      " [   1  173 1109    3   20   22  101    3    1   31]\n",
      " [   0  174  292   34    6    4   46    1    1   15]\n",
      " [   0  116  115    0  224    2   49    1    1   30]\n",
      " [   0   35  222    1    4  371   19    6    4    5]\n",
      " [   0  175   98    3    9    7  715    0    0   42]\n",
      " [   0  173   99    2    6    7   20  124    0   13]\n",
      " [   0  152   78    0    4   10    7    8  100   27]\n",
      " [   0  295  120    2    5    7  115    5    1  280]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=7000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier(n_estimators=500, criterion = \"gini\"))  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = RF_pipeline.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ca003f3464d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "plot_cm(dt_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

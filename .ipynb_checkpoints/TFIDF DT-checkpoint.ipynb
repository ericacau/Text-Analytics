{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing & utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# text handling \n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# models for classification\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Erica\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(pipeline, X_test, y_test):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plot_confusion_matrix(pipeline, X_test, y_test)  \n",
    "    plt.xticks(rotation=45, fontsize = 10)\n",
    "    plt.yticks(rotation=0, fontsize = 8)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "def eval_accuracy (pred, test):\n",
    "    correct = 0\n",
    "    for prediction,true_label in zip(predictions, y_test):\n",
    "        if prediction==true_label:\n",
    "            correct += 1\n",
    "    return (correct/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/books_def.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36638 entries, Suzanne Collins to Mimi Baird|Eve Claxton\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   book_desc    36638 non-null  object \n",
      " 1   book_rating  36638 non-null  float64\n",
      " 2   book_title   36638 non-null  object \n",
      " 3   genres       36638 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_authors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Suzanne Collins</th>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J.K. Rowling|Mary GrandPré</th>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>4.48</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harper Lee</th>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>4.27</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephenie Meyer</th>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>3.58</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markus Zusak</th>\n",
       "      <td>Trying to make sense of the horrors of World W...</td>\n",
       "      <td>4.36</td>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>Historical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    book_desc  \\\n",
       "book_authors                                                                    \n",
       "Suzanne Collins             Winning will make you famous. Losing means cer...   \n",
       "J.K. Rowling|Mary GrandPré  There is a door at the end of a silent corrido...   \n",
       "Harper Lee                  The unforgettable novel of a childhood in a sl...   \n",
       "Stephenie Meyer             About three things I was absolutely positive.F...   \n",
       "Markus Zusak                Trying to make sense of the horrors of World W...   \n",
       "\n",
       "                            book_rating  \\\n",
       "book_authors                              \n",
       "Suzanne Collins                    4.33   \n",
       "J.K. Rowling|Mary GrandPré         4.48   \n",
       "Harper Lee                         4.27   \n",
       "Stephenie Meyer                    3.58   \n",
       "Markus Zusak                       4.36   \n",
       "\n",
       "                                                           book_title  \\\n",
       "book_authors                                                            \n",
       "Suzanne Collins                                      The Hunger Games   \n",
       "J.K. Rowling|Mary GrandPré  Harry Potter and the Order of the Phoenix   \n",
       "Harper Lee                                      To Kill a Mockingbird   \n",
       "Stephenie Meyer                                              Twilight   \n",
       "Markus Zusak                                           The Book Thief   \n",
       "\n",
       "                                 genres  \n",
       "book_authors                             \n",
       "Suzanne Collins             Young Adult  \n",
       "J.K. Rowling|Mary GrandPré      Fantasy  \n",
       "Harper Lee                     Classics  \n",
       "Stephenie Meyer             Young Adult  \n",
       "Markus Zusak                 Historical  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Winning will make you famous. Losing means cer...\n",
       "1        There is a door at the end of a silent corrido...\n",
       "2        The unforgettable novel of a childhood in a sl...\n",
       "3        About three things I was absolutely positive.F...\n",
       "4        Trying to make sense of the horrors of World W...\n",
       "                               ...                        \n",
       "36633    A brilliant, provocative novel about an artist...\n",
       "36634    Avi Steinberg is stumped. After defecting from...\n",
       "36635    In this fearless and half-crazy story, Howard ...\n",
       "36636    From the icons of the game to the players who ...\n",
       "36637    Soon to be a major motion picture, from Brad P...\n",
       "Name: book_desc, Length: 36638, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"book_desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggo testi & etichette\n",
    "X = df[\"book_desc\"]\n",
    "y = df[\"genres\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Winner of the 2007 BookBrowse Award for Most Popular Book.An atmospheric, gritty, and compelling novel of star-crossed lovers, set in the circus world circa 1932, by the bestselling author of Riding Lessons. When Jacob Jankowski, recently orphaned and suddenly adrift, jumps onto a passing train, he enters a world of freaks, drifters, and misfits, a second-rate circus struggling to survive during the Great Depression, making one-night stands in town after endless town. A veterinary student who almost earned his degree, Jacob is put in charge of caring for the circus menagerie. It is there that he meets Marlena, the beautiful young star of the equestrian act, who is married to August, the charismatic but twisted animal trainer. He also meets Rosie, an elephant who seems untrainable until he discovers a way to reach her. Beautifully written, Water for Elephants is illuminated by a wonderful sense of time and place. It tells a story of a love between two people that overcomes incredible odds in a world in which even love is a luxury that few can afford.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 50\n",
    "X_train[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fiction'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[sample_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def spacy_nlp_tokenizer(text):\n",
    "    # substituting all space characters with a single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub('\\r+', ' ', text)\n",
    "    # removing Url\n",
    "    text = re.sub(r\"\\S*https?:\\S*\", \"\", text, flags=re.MULTILINE)\n",
    "    #removing mention\n",
    "    text = re.sub(r'@[\\w]+', \"\", text, flags=re.MULTILINE)\n",
    "    doc = nlp(text)\n",
    "    # lemmatizing tokens and lowering case\n",
    "    lemmas = [token.lemma_.lower() for token in doc]\n",
    "    \n",
    "    # removing stopwords and punctuations\n",
    "    lemmas_nostop = [token for token in lemmas if token not in stopword_list and token not in punctuations]\n",
    "\n",
    "    # creating ngrams\n",
    "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas_nostop,2)]\n",
    "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas_nostop,3)]\n",
    "    \n",
    "    all_tokens = list()\n",
    "    all_tokens.extend(lemmas_nostop)\n",
    "    all_tokens.extend(lemma_bigrams)\n",
    "    all_tokens.extend(lemma_trigrams)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickle/svm_train_tok.pkl',mode='br') as inputfile:\n",
    "    X_train_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/svm_test_tok.pkl',mode='br') as inputfile:\n",
    "    X_test_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/vect.pkl',mode='br') as inputfile:\n",
    "    vect = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  25646 Genres:  25646\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \", len(X_train), \"Genres: \", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  10992 Genres:  10992\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \", len(X_test), \"Genres: \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fiction', 'Fantasy', 'Nonfiction', 'Romance', 'Science Fiction', 'Historical', 'Mystery', 'Classics', 'Sequential Art', 'Young Adult'} \n",
      " {'Fiction', 'Romance', 'Nonfiction', 'Fantasy', 'Science Fiction', 'Historical', 'Mystery', 'Classics', 'Sequential Art', 'Young Adult'}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_test), \"\\n\", set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=1000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', DecisionTreeClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = dt_pipeline.predict(X_test_tok)\n",
    "predictions_train = dt_pipeline.predict(X_train_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification report training :')\n",
    "print(classification_report(y_train, predictions_train))\n",
    "\n",
    "print('Confusion matrix training :')\n",
    "cm = confusion_matrix(y_train, predictions_train)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df = 5)), #tokenization\n",
    "    ('sel', SelectKBest(chi2, k=\"all\")),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', DecisionTreeClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train,y_train)\n",
    "predictions_train = dt_pipeline.predict(X_train)\n",
    "predictions = dt_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification report training :')\n",
    "print(classification_report(y_train, predictions_train))\n",
    "\n",
    "print('Confusion matrix training :')\n",
    "cm = confusion_matrix(y_train, predictions_train)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = vect\n",
    "selector = dt_pipeline.named_steps['sel']\n",
    "classifier = dt_pipeline.named_steps['learner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tokenizer.get_feature_names()\n",
    "feats_w_score = list()\n",
    "for index,(selected,score) in enumerate(zip(selector.get_support(),selector.scores_)):\n",
    "    feats_w_score.append((score,selected,feature_names[index]))\n",
    "feats_w_score = sorted(feats_w_score)\n",
    "len(feats_w_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w_score[-100:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w_score[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

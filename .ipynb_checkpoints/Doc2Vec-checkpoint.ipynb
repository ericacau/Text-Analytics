{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "import multiprocessing\n",
    "from sklearn import model_selection, svm\n",
    "cores = multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"books_def.csv\", index_col=0)\n",
    "df = df.reset_index()\n",
    "for col in ['book_authors', 'book_rating', 'book_title']:\n",
    "    del df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_desc</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying to make sense of the horrors of World W...</td>\n",
       "      <td>Historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36633</th>\n",
       "      <td>A brilliant, provocative novel about an artist...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36634</th>\n",
       "      <td>Avi Steinberg is stumped. After defecting from...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36635</th>\n",
       "      <td>In this fearless and half-crazy story, Howard ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36636</th>\n",
       "      <td>From the icons of the game to the players who ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36637</th>\n",
       "      <td>Soon to be a major motion picture, from Brad P...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36638 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               book_desc       genres\n",
       "0      Winning will make you famous. Losing means cer...  Young Adult\n",
       "1      There is a door at the end of a silent corrido...      Fantasy\n",
       "2      The unforgettable novel of a childhood in a sl...     Classics\n",
       "3      About three things I was absolutely positive.F...  Young Adult\n",
       "4      Trying to make sense of the horrors of World W...   Historical\n",
       "...                                                  ...          ...\n",
       "36633  A brilliant, provocative novel about an artist...      Fiction\n",
       "36634  Avi Steinberg is stumped. After defecting from...   Nonfiction\n",
       "36635  In this fearless and half-crazy story, Howard ...   Nonfiction\n",
       "36636  From the icons of the game to the players who ...   Nonfiction\n",
       "36637  Soon to be a major motion picture, from Brad P...   Nonfiction\n",
       "\n",
       "[36638 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('x', '')\n",
    "    return text\n",
    "df['book_desc'] = df['book_desc'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags=[r.genres] per motivi ignoti SI PRENDE L'INDICE\n",
    "df['to_ind'] = df['genres']\n",
    "df = df.set_index('to_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_desc</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_ind</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Young Adult</th>\n",
       "      <td>winning will make you famous. losing means cer...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>there is a door at the end of a silent corrido...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classics</th>\n",
       "      <td>the unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Adult</th>\n",
       "      <td>about three things i was absolutely positive.f...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Historical</th>\n",
       "      <td>trying to make sense of the horrors of world w...</td>\n",
       "      <td>Historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction</th>\n",
       "      <td>a brilliant, provocative novel about an artist...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfiction</th>\n",
       "      <td>avi steinberg is stumped. after defecting from...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfiction</th>\n",
       "      <td>in this fearless and half-crazy story, howard ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfiction</th>\n",
       "      <td>from the icons of the game to the players who ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfiction</th>\n",
       "      <td>soon to be a major motion picture, from brad p...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36638 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     book_desc       genres\n",
       "to_ind                                                                     \n",
       "Young Adult  winning will make you famous. losing means cer...  Young Adult\n",
       "Fantasy      there is a door at the end of a silent corrido...      Fantasy\n",
       "Classics     the unforgettable novel of a childhood in a sl...     Classics\n",
       "Young Adult  about three things i was absolutely positive.f...  Young Adult\n",
       "Historical   trying to make sense of the horrors of world w...   Historical\n",
       "...                                                        ...          ...\n",
       "Fiction      a brilliant, provocative novel about an artist...      Fiction\n",
       "Nonfiction   avi steinberg is stumped. after defecting from...   Nonfiction\n",
       "Nonfiction   in this fearless and half-crazy story, howard ...   Nonfiction\n",
       "Nonfiction   from the icons of the game to the players who ...   Nonfiction\n",
       "Nonfiction   soon to be a major motion picture, from brad p...   Nonfiction\n",
       "\n",
       "[36638 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "train_tagged = train.apply(lambda r: TaggedDocument(words=tokenize_text(r['book_desc']), tags=[r.genres]), axis=1)\n",
    "\n",
    "test_tagged = test.apply(lambda r: TaggedDocument(words=tokenize_text(r['book_desc']), tags=[r.genres]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, epochs=200)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "#model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#for epoch in range(30):\n",
    " #   model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "  #  model_dbow.alpha -= 0.002\n",
    "   # model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "#y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#logreg = LogisticRegression(n_jobs=1, C=1e5,  max_iter=10000))\n",
    "#logreg.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = logreg.predict(X_test)\n",
    "\n",
    "#print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "#print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "#SVM.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = SVM.predict(X_test)\n",
    "\n",
    "#print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "#print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = RandomForestClassifier(bootstrap=True)\n",
    "\n",
    "#clf = rand_search.best_estimator_\n",
    "\n",
    "#clf = clf.fit(X_train, y_train)\n",
    "#y_pred = clf.predict(X_test)\n",
    "#print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "#print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed Memory (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25646/25646 [00:00<00:00, 2742030.65it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=5, workers=15, alpha=0.065, min_alpha=0.065)\n",
    "#model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=5, workers=15, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25646/25646 [00:00<00:00, 7123650.36it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 7134044.33it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 7626169.47it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 7505904.71it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 7115639.37it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6727991.02it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 7254813.54it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6894002.46it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6313736.01it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6638716.31it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6657617.16it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6277992.32it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6225309.36it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6020098.52it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5637985.24it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6128133.10it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5868364.45it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6188420.23it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6186640.62it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5833990.69it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6315589.50it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6032590.45it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5583551.54it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5754098.66it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5918736.68it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6078955.66it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 6219909.82it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5735077.86it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5806278.76it/s]\n",
      "100%|██████████| 25646/25646 [00:00<00:00, 5794393.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 45s, sys: 20.7 s, total: 5min 5s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5385735080058224\n",
      "Testing F1 score: 0.5439093621982938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "y_pred = SVM.predict(X_test)\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeee ciao\n",
    "\n",
    "#params =param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    " #             'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              #'kernel': ['rbf']}\n",
    "#SVM = svm.SVC()\n",
    "#rand_search = RandomizedSearchCV(SVM, params, verbose=0, random_state=42)\n",
    "#rand_search.fit(X_train, y_train)\n",
    "#clf = rand_search.best_estimator_\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = SVM.predict(X_test)\n",
    "\n",
    "#print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "#p#rint('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5376637554585153\n",
      "Testing F1 score: 0.5472231879510425\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5,  max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.4666120815138282\n",
      "Testing F1 score: 0.4152750611251759\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(bootstrap=True)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/federico/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: /Users/federico/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-219f903ef2c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/federico/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: /Users/federico/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d7821364cde5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Pads sequences to the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_tokenized_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_test_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_tokenized_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#default batch size 32\n",
    "#Optional Int, maximum length of all sequences. \n",
    "#If not provided, sequences will be padded to the length of the longest individual sequence.\n",
    "maxlen = 100 \n",
    "embed_size = 64 \n",
    "#Pads sequences to the same length.\n",
    "X_train_final = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_test_final = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "input = Input(shape=(maxlen, )) \n",
    "x   =  Embedding(max_features, embed_size)(input)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(10, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(264, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"softmax\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n",
    "\n",
    "model = Model(inputs=input, outputs=x)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "cnn5 = model.fit(X_train_final, y_train, epochs=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "#model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_vectors(model, tagged_docs):\n",
    "#    sents = tagged_docs.values\n",
    " #   targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    " #   return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "#y_test, X_test = get_vectors(new_model, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.1826783114992722\n",
      "Testing F1 score: 0.13060293283431898\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "#SVM.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = SVM.predict(X_test)\n",
    "\n",
    "#print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "#print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.12527292576419213\n",
      "Testing F1 score: 0.11406939588161567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#logreg.fit(X_train, y_train)\n",
    "#y_pred = logreg.predict(X_test)\n",
    "#print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "#print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.18340611353711792\n",
      "Testing F1 score: 0.1421811719743764\n"
     ]
    }
   ],
   "source": [
    "#clf = RandomForestClassifier(bootstrap=True)\n",
    "\n",
    "#clf = clf.fit(X_train, y_train)\n",
    "#y_pred = clf.predict(X_test)\n",
    "#print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "#print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

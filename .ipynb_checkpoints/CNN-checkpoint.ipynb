{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.layers import Embedding \n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/books_def.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels= encoder.fit_transform(df['genres'].values)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_authors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jack London</th>\n",
       "      <td>Of all Jack London's fictions none have been a...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>The Call of the Wild, White Fang, and Other St...</td>\n",
       "      <td>Classics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Constantinos P. Cavafis|Edmund Keeley|Philip Sherrard|George Savidis|C.P. Cavafy</th>\n",
       "      <td>C.P. Cavafy (1863-1933) lived in relative obsc...</td>\n",
       "      <td>4.38</td>\n",
       "      <td>C. P. Cavafy: Collected Poems</td>\n",
       "      <td>Classics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sinclair Lewis</th>\n",
       "      <td>With Commentary by E. M. Forster, Dorothy Park...</td>\n",
       "      <td>3.76</td>\n",
       "      <td>Main Street</td>\n",
       "      <td>Classics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colette</th>\n",
       "      <td>In Ripening Seed Colette captures that preciou...</td>\n",
       "      <td>3.54</td>\n",
       "      <td>The Ripening Seed</td>\n",
       "      <td>Classics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.S. Eliot|Mary Karr</th>\n",
       "      <td>Also includes Prufrock and Other Observations,...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>The Waste Land and Other Writings</td>\n",
       "      <td>Classics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert Muchamore</th>\n",
       "      <td>CHERUB agents are highly trained, extremely ta...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Maximum Security</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrienne Torrisi</th>\n",
       "      <td>Sometimes you think you know exactly what life...</td>\n",
       "      <td>3.78</td>\n",
       "      <td>Accidental Crush</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Katherine Paterson</th>\n",
       "      <td>Jess Aarons' greatest ambition is to be the fa...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>Bridge To Terabithia</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irene Hunt</th>\n",
       "      <td>The Newbery Award-winning novel From the autho...</td>\n",
       "      <td>4.02</td>\n",
       "      <td>Up a Road Slowly</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suzanne Collins</th>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36638 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            book_desc  \\\n",
       "book_authors                                                                                            \n",
       "Jack London                                         Of all Jack London's fictions none have been a...   \n",
       "Constantinos P. Cavafis|Edmund Keeley|Philip Sh...  C.P. Cavafy (1863-1933) lived in relative obsc...   \n",
       "Sinclair Lewis                                      With Commentary by E. M. Forster, Dorothy Park...   \n",
       "Colette                                             In Ripening Seed Colette captures that preciou...   \n",
       "T.S. Eliot|Mary Karr                                Also includes Prufrock and Other Observations,...   \n",
       "...                                                                                               ...   \n",
       "Robert Muchamore                                    CHERUB agents are highly trained, extremely ta...   \n",
       "Adrienne Torrisi                                    Sometimes you think you know exactly what life...   \n",
       "Katherine Paterson                                  Jess Aarons' greatest ambition is to be the fa...   \n",
       "Irene Hunt                                          The Newbery Award-winning novel From the autho...   \n",
       "Suzanne Collins                                     Winning will make you famous. Losing means cer...   \n",
       "\n",
       "                                                    book_rating  \\\n",
       "book_authors                                                      \n",
       "Jack London                                                3.98   \n",
       "Constantinos P. Cavafis|Edmund Keeley|Philip Sh...         4.38   \n",
       "Sinclair Lewis                                             3.76   \n",
       "Colette                                                    3.54   \n",
       "T.S. Eliot|Mary Karr                                       4.21   \n",
       "...                                                         ...   \n",
       "Robert Muchamore                                           4.25   \n",
       "Adrienne Torrisi                                           3.78   \n",
       "Katherine Paterson                                         3.98   \n",
       "Irene Hunt                                                 4.02   \n",
       "Suzanne Collins                                            4.33   \n",
       "\n",
       "                                                                                           book_title  \\\n",
       "book_authors                                                                                            \n",
       "Jack London                                         The Call of the Wild, White Fang, and Other St...   \n",
       "Constantinos P. Cavafis|Edmund Keeley|Philip Sh...                      C. P. Cavafy: Collected Poems   \n",
       "Sinclair Lewis                                                                            Main Street   \n",
       "Colette                                                                             The Ripening Seed   \n",
       "T.S. Eliot|Mary Karr                                                The Waste Land and Other Writings   \n",
       "...                                                                                               ...   \n",
       "Robert Muchamore                                                                     Maximum Security   \n",
       "Adrienne Torrisi                                                                     Accidental Crush   \n",
       "Katherine Paterson                                                               Bridge To Terabithia   \n",
       "Irene Hunt                                                                           Up a Road Slowly   \n",
       "Suzanne Collins                                                                      The Hunger Games   \n",
       "\n",
       "                                                         genres  label  \n",
       "book_authors                                                            \n",
       "Jack London                                            Classics      0  \n",
       "Constantinos P. Cavafis|Edmund Keeley|Philip Sh...     Classics      0  \n",
       "Sinclair Lewis                                         Classics      0  \n",
       "Colette                                                Classics      0  \n",
       "T.S. Eliot|Mary Karr                                   Classics      0  \n",
       "...                                                         ...    ...  \n",
       "Robert Muchamore                                    Young Adult      9  \n",
       "Adrienne Torrisi                                    Young Adult      9  \n",
       "Katherine Paterson                                  Young Adult      9  \n",
       "Irene Hunt                                          Young Adult      9  \n",
       "Suzanne Collins                                     Young Adult      9  \n",
       "\n",
       "[36638 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = labels\n",
    "df = df.sort_values(by=[\"label\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['book_desc'].values, df['label'].values, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7f518ee7a4bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#Transforms each text in texts to a sequence of integers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlist_tokenized_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# In how many documents each word occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mwcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "#Transforms each text in texts to a sequence of integers.\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default batch size 32\n",
    "#Optional Int, maximum length of all sequences. \n",
    "#If not provided, sequences will be padded to the length of the longest individual sequence.\n",
    "maxlen = 100 \n",
    "embed_size = 64 \n",
    "#Pads sequences to the same length.\n",
    "X_train_final = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_test_final = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen, )) \n",
    "x   =  Embedding(max_features, embed_size)(input)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(10, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(264, activation=\"relu\", kernel_regularizer=l2(0.01), )(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"softmax\", kernel_regularizer=l2(0.01))(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input, outputs=x)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 3.2211 - accuracy: 0.1663 - val_loss: 2.3654 - val_accuracy: 0.1867\n",
      "Epoch 2/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.3254 - accuracy: 0.1675 - val_loss: 2.2673 - val_accuracy: 0.1867\n",
      "Epoch 3/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.2628 - accuracy: 0.1774 - val_loss: 2.2444 - val_accuracy: 0.1951\n",
      "Epoch 4/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 2.2334 - accuracy: 0.1793 - val_loss: 2.2406 - val_accuracy: 0.1951\n",
      "Epoch 5/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 2.2042 - accuracy: 0.1812 - val_loss: 2.2146 - val_accuracy: 0.1867\n",
      "Epoch 6/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.1885 - accuracy: 0.1841 - val_loss: 2.2110 - val_accuracy: 0.1951\n",
      "Epoch 7/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 2.1669 - accuracy: 0.1803 - val_loss: 2.2203 - val_accuracy: 0.1578\n",
      "Epoch 8/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 2.1396 - accuracy: 0.1862 - val_loss: 2.2383 - val_accuracy: 0.1951\n",
      "Epoch 9/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 2.0993 - accuracy: 0.1809 - val_loss: 2.2500 - val_accuracy: 0.1851\n",
      "Epoch 10/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.9756 - accuracy: 0.2130 - val_loss: 2.5827 - val_accuracy: 0.1269\n",
      "Epoch 11/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 1.8066 - accuracy: 0.2787 - val_loss: 2.8221 - val_accuracy: 0.1316\n",
      "Epoch 12/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.6954 - accuracy: 0.3078 - val_loss: 3.1961 - val_accuracy: 0.1374\n",
      "Epoch 13/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.6326 - accuracy: 0.3238 - val_loss: 3.4312 - val_accuracy: 0.1248\n",
      "Epoch 14/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.5827 - accuracy: 0.3310 - val_loss: 3.7676 - val_accuracy: 0.1421\n",
      "Epoch 15/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.5456 - accuracy: 0.3478 - val_loss: 4.0344 - val_accuracy: 0.1295\n",
      "Epoch 16/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.5123 - accuracy: 0.3652 - val_loss: 4.3073 - val_accuracy: 0.1295\n",
      "Epoch 17/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.4758 - accuracy: 0.3982 - val_loss: 4.4694 - val_accuracy: 0.1374\n",
      "Epoch 18/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.4459 - accuracy: 0.4083 - val_loss: 4.5276 - val_accuracy: 0.1290\n",
      "Epoch 19/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 1.4140 - accuracy: 0.4291 - val_loss: 4.9821 - val_accuracy: 0.1400\n",
      "Epoch 20/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.3808 - accuracy: 0.4323 - val_loss: 5.1294 - val_accuracy: 0.1458\n",
      "Epoch 21/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.3586 - accuracy: 0.4526 - val_loss: 5.0376 - val_accuracy: 0.1384\n",
      "Epoch 22/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.3349 - accuracy: 0.4593 - val_loss: 5.3819 - val_accuracy: 0.1253\n",
      "Epoch 23/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.3122 - accuracy: 0.4674 - val_loss: 5.5949 - val_accuracy: 0.1201\n",
      "Epoch 24/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.2917 - accuracy: 0.4793 - val_loss: 5.7156 - val_accuracy: 0.1426\n",
      "Epoch 25/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.2735 - accuracy: 0.4831 - val_loss: 6.1141 - val_accuracy: 0.1369\n",
      "Epoch 26/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.2560 - accuracy: 0.4847 - val_loss: 6.2741 - val_accuracy: 0.1390\n",
      "Epoch 27/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.2454 - accuracy: 0.4939 - val_loss: 6.3476 - val_accuracy: 0.1374\n",
      "Epoch 28/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.2291 - accuracy: 0.4910 - val_loss: 6.6310 - val_accuracy: 0.1311\n",
      "Epoch 29/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.2186 - accuracy: 0.5019 - val_loss: 6.5647 - val_accuracy: 0.1295\n",
      "Epoch 30/200\n",
      "239/239 [==============================] - 5s 20ms/step - loss: 1.2141 - accuracy: 0.4997 - val_loss: 6.7150 - val_accuracy: 0.1285\n",
      "Epoch 31/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.2019 - accuracy: 0.5016 - val_loss: 6.7150 - val_accuracy: 0.1348\n",
      "Epoch 32/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 1.1936 - accuracy: 0.5064 - val_loss: 7.0342 - val_accuracy: 0.1285\n",
      "Epoch 33/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 1.1853 - accuracy: 0.5116 - val_loss: 6.8970 - val_accuracy: 0.1369\n",
      "Epoch 34/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1695 - accuracy: 0.5226 - val_loss: 7.0353 - val_accuracy: 0.1369\n",
      "Epoch 35/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1633 - accuracy: 0.5272 - val_loss: 7.1783 - val_accuracy: 0.1332\n",
      "Epoch 36/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1705 - accuracy: 0.5169 - val_loss: 7.3302 - val_accuracy: 0.1279\n",
      "Epoch 37/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1650 - accuracy: 0.5150 - val_loss: 7.4327 - val_accuracy: 0.1279\n",
      "Epoch 38/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1542 - accuracy: 0.5237 - val_loss: 7.5137 - val_accuracy: 0.1232\n",
      "Epoch 39/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1542 - accuracy: 0.5305 - val_loss: 7.5142 - val_accuracy: 0.1274\n",
      "Epoch 40/200\n",
      "239/239 [==============================] - 5s 21ms/step - loss: 1.1464 - accuracy: 0.5294 - val_loss: 7.5455 - val_accuracy: 0.1238\n",
      "Epoch 41/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 1.1513 - accuracy: 0.5311 - val_loss: 7.4536 - val_accuracy: 0.1374\n",
      "Epoch 42/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1397 - accuracy: 0.5376 - val_loss: 7.2068 - val_accuracy: 0.1358\n",
      "Epoch 43/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 1.1201 - accuracy: 0.5436 - val_loss: 7.5839 - val_accuracy: 0.1259\n",
      "Epoch 44/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1337 - accuracy: 0.5374 - val_loss: 7.4884 - val_accuracy: 0.1274\n",
      "Epoch 45/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 1.1176 - accuracy: 0.5553 - val_loss: 7.3445 - val_accuracy: 0.1332\n",
      "Epoch 46/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 1.1149 - accuracy: 0.5601 - val_loss: 7.7716 - val_accuracy: 0.1353\n",
      "Epoch 47/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1229 - accuracy: 0.5614 - val_loss: 7.6836 - val_accuracy: 0.1363\n",
      "Epoch 48/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.1213 - accuracy: 0.5620 - val_loss: 7.7440 - val_accuracy: 0.1358\n",
      "Epoch 49/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 1.0994 - accuracy: 0.5748 - val_loss: 7.6996 - val_accuracy: 0.1332\n",
      "Epoch 50/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 1.1117 - accuracy: 0.5786 - val_loss: 7.6441 - val_accuracy: 0.1332\n",
      "Epoch 51/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 1.0912 - accuracy: 0.5883 - val_loss: 7.8261 - val_accuracy: 0.1337\n",
      "Epoch 52/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 1.1015 - accuracy: 0.5856 - val_loss: 8.0692 - val_accuracy: 0.1316\n",
      "Epoch 53/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 1.0730 - accuracy: 0.6176 - val_loss: 8.1507 - val_accuracy: 0.1416\n",
      "Epoch 54/200\n",
      "239/239 [==============================] - 5s 20ms/step - loss: 1.0764 - accuracy: 0.6090 - val_loss: 8.3750 - val_accuracy: 0.1411\n",
      "Epoch 55/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 1.0657 - accuracy: 0.6188 - val_loss: 8.2289 - val_accuracy: 0.1395\n",
      "Epoch 56/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.0566 - accuracy: 0.6279 - val_loss: 8.2766 - val_accuracy: 0.1332\n",
      "Epoch 57/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.0484 - accuracy: 0.6292 - val_loss: 8.5768 - val_accuracy: 0.1442\n",
      "Epoch 58/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.0295 - accuracy: 0.6386 - val_loss: 8.9182 - val_accuracy: 0.1384\n",
      "Epoch 59/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.0163 - accuracy: 0.6439 - val_loss: 9.0101 - val_accuracy: 0.1290\n",
      "Epoch 60/200\n",
      "239/239 [==============================] - 5s 20ms/step - loss: 1.0209 - accuracy: 0.6455 - val_loss: 8.5101 - val_accuracy: 0.1400\n",
      "Epoch 61/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.0116 - accuracy: 0.6470 - val_loss: 8.4189 - val_accuracy: 0.1379\n",
      "Epoch 62/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.0141 - accuracy: 0.6513 - val_loss: 8.7569 - val_accuracy: 0.1432\n",
      "Epoch 63/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.0013 - accuracy: 0.6500 - val_loss: 9.1757 - val_accuracy: 0.1337\n",
      "Epoch 64/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.0051 - accuracy: 0.6515 - val_loss: 8.7567 - val_accuracy: 0.1353\n",
      "Epoch 65/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9952 - accuracy: 0.6532 - val_loss: 8.7598 - val_accuracy: 0.1432\n",
      "Epoch 66/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9959 - accuracy: 0.6547 - val_loss: 9.0904 - val_accuracy: 0.1437\n",
      "Epoch 67/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.0123 - accuracy: 0.6561 - val_loss: 9.2693 - val_accuracy: 0.1405\n",
      "Epoch 68/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.0139 - accuracy: 0.6376 - val_loss: 8.7524 - val_accuracy: 0.1390\n",
      "Epoch 69/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.9773 - accuracy: 0.6707 - val_loss: 9.3972 - val_accuracy: 0.1337\n",
      "Epoch 70/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.9724 - accuracy: 0.6762 - val_loss: 9.4439 - val_accuracy: 0.1395\n",
      "Epoch 71/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.9777 - accuracy: 0.6639 - val_loss: 9.2842 - val_accuracy: 0.1432\n",
      "Epoch 72/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.9880 - accuracy: 0.6564 - val_loss: 8.9082 - val_accuracy: 0.1316\n",
      "Epoch 73/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.9657 - accuracy: 0.6691 - val_loss: 9.5548 - val_accuracy: 0.1442\n",
      "Epoch 74/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9701 - accuracy: 0.6692 - val_loss: 9.7082 - val_accuracy: 0.1421\n",
      "Epoch 75/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.9702 - accuracy: 0.6742 - val_loss: 9.4401 - val_accuracy: 0.1300\n",
      "Epoch 76/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9647 - accuracy: 0.6814 - val_loss: 9.4817 - val_accuracy: 0.1442\n",
      "Epoch 77/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.9605 - accuracy: 0.6737 - val_loss: 9.6535 - val_accuracy: 0.1384\n",
      "Epoch 78/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.9622 - accuracy: 0.6711 - val_loss: 9.3808 - val_accuracy: 0.1411\n",
      "Epoch 79/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9451 - accuracy: 0.6730 - val_loss: 9.8532 - val_accuracy: 0.1379\n",
      "Epoch 80/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9520 - accuracy: 0.6790 - val_loss: 9.7697 - val_accuracy: 0.1285\n",
      "Epoch 81/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9522 - accuracy: 0.6753 - val_loss: 9.2141 - val_accuracy: 0.1405\n",
      "Epoch 82/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.9509 - accuracy: 0.6755 - val_loss: 9.9711 - val_accuracy: 0.1426\n",
      "Epoch 83/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9449 - accuracy: 0.6778 - val_loss: 9.6089 - val_accuracy: 0.1395\n",
      "Epoch 84/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9476 - accuracy: 0.6826 - val_loss: 9.7536 - val_accuracy: 0.1300\n",
      "Epoch 85/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9460 - accuracy: 0.6753 - val_loss: 9.8328 - val_accuracy: 0.1390\n",
      "Epoch 86/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.9347 - accuracy: 0.6870 - val_loss: 9.3056 - val_accuracy: 0.1379\n",
      "Epoch 87/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.9448 - accuracy: 0.6801 - val_loss: 9.5287 - val_accuracy: 0.1421\n",
      "Epoch 88/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9274 - accuracy: 0.6897 - val_loss: 9.8761 - val_accuracy: 0.1411\n",
      "Epoch 89/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9479 - accuracy: 0.6702 - val_loss: 10.0967 - val_accuracy: 0.1447\n",
      "Epoch 90/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9278 - accuracy: 0.6929 - val_loss: 9.4509 - val_accuracy: 0.1358\n",
      "Epoch 91/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9417 - accuracy: 0.6813 - val_loss: 9.7281 - val_accuracy: 0.1442\n",
      "Epoch 92/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9376 - accuracy: 0.6807 - val_loss: 9.8109 - val_accuracy: 0.1400\n",
      "Epoch 93/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9262 - accuracy: 0.6866 - val_loss: 10.1917 - val_accuracy: 0.1447\n",
      "Epoch 94/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 0.9205 - accuracy: 0.6881 - val_loss: 10.2305 - val_accuracy: 0.1390\n",
      "Epoch 95/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9107 - accuracy: 0.6950 - val_loss: 10.3686 - val_accuracy: 0.1337\n",
      "Epoch 96/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.9277 - accuracy: 0.6835 - val_loss: 9.8166 - val_accuracy: 0.1416\n",
      "Epoch 97/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.9273 - accuracy: 0.6826 - val_loss: 9.8676 - val_accuracy: 0.1489\n",
      "Epoch 98/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9283 - accuracy: 0.6774 - val_loss: 10.2927 - val_accuracy: 0.1374\n",
      "Epoch 99/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9272 - accuracy: 0.6830 - val_loss: 10.2008 - val_accuracy: 0.1390\n",
      "Epoch 100/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9257 - accuracy: 0.6835 - val_loss: 10.1156 - val_accuracy: 0.1416\n",
      "Epoch 101/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9160 - accuracy: 0.6906 - val_loss: 10.0571 - val_accuracy: 0.1342\n",
      "Epoch 102/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9223 - accuracy: 0.6805 - val_loss: 10.2601 - val_accuracy: 0.1437\n",
      "Epoch 103/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9105 - accuracy: 0.6901 - val_loss: 10.2130 - val_accuracy: 0.1363\n",
      "Epoch 104/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9155 - accuracy: 0.6879 - val_loss: 10.4287 - val_accuracy: 0.1342\n",
      "Epoch 105/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9084 - accuracy: 0.6877 - val_loss: 10.6573 - val_accuracy: 0.1342\n",
      "Epoch 106/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9083 - accuracy: 0.6990 - val_loss: 10.2971 - val_accuracy: 0.1311\n",
      "Epoch 107/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9127 - accuracy: 0.6835 - val_loss: 10.2833 - val_accuracy: 0.1358\n",
      "Epoch 108/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8996 - accuracy: 0.6884 - val_loss: 10.3028 - val_accuracy: 0.1421\n",
      "Epoch 109/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9081 - accuracy: 0.6944 - val_loss: 10.6085 - val_accuracy: 0.1437\n",
      "Epoch 110/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9009 - accuracy: 0.6985 - val_loss: 10.1716 - val_accuracy: 0.1463\n",
      "Epoch 111/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8891 - accuracy: 0.6977 - val_loss: 10.3488 - val_accuracy: 0.1447\n",
      "Epoch 112/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9028 - accuracy: 0.6902 - val_loss: 10.4485 - val_accuracy: 0.1390\n",
      "Epoch 113/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8980 - accuracy: 0.6894 - val_loss: 10.8018 - val_accuracy: 0.1369\n",
      "Epoch 114/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8971 - accuracy: 0.6998 - val_loss: 11.0187 - val_accuracy: 0.1384\n",
      "Epoch 115/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8902 - accuracy: 0.6989 - val_loss: 11.1284 - val_accuracy: 0.1447\n",
      "Epoch 116/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.9007 - accuracy: 0.6946 - val_loss: 10.5609 - val_accuracy: 0.1363\n",
      "Epoch 117/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8950 - accuracy: 0.6978 - val_loss: 11.1436 - val_accuracy: 0.1337\n",
      "Epoch 118/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8917 - accuracy: 0.7036 - val_loss: 10.9335 - val_accuracy: 0.1295\n",
      "Epoch 119/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8976 - accuracy: 0.6904 - val_loss: 11.1909 - val_accuracy: 0.1342\n",
      "Epoch 120/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8785 - accuracy: 0.7071 - val_loss: 11.3770 - val_accuracy: 0.1489\n",
      "Epoch 121/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8794 - accuracy: 0.6972 - val_loss: 11.1874 - val_accuracy: 0.1442\n",
      "Epoch 122/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8793 - accuracy: 0.7066 - val_loss: 11.4440 - val_accuracy: 0.1405\n",
      "Epoch 123/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8904 - accuracy: 0.6964 - val_loss: 10.9461 - val_accuracy: 0.1374\n",
      "Epoch 124/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8847 - accuracy: 0.7078 - val_loss: 11.2760 - val_accuracy: 0.1510\n",
      "Epoch 125/200\n",
      "239/239 [==============================] - 5s 20ms/step - loss: 0.8721 - accuracy: 0.7070 - val_loss: 11.2303 - val_accuracy: 0.1421\n",
      "Epoch 126/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8769 - accuracy: 0.7035 - val_loss: 11.2153 - val_accuracy: 0.1363\n",
      "Epoch 127/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8735 - accuracy: 0.6985 - val_loss: 11.7920 - val_accuracy: 0.1479\n",
      "Epoch 128/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8730 - accuracy: 0.7040 - val_loss: 11.4285 - val_accuracy: 0.1400\n",
      "Epoch 129/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8878 - accuracy: 0.6984 - val_loss: 11.3403 - val_accuracy: 0.1552\n",
      "Epoch 130/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8862 - accuracy: 0.6959 - val_loss: 11.1684 - val_accuracy: 0.1474\n",
      "Epoch 131/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8659 - accuracy: 0.7125 - val_loss: 11.4123 - val_accuracy: 0.1374\n",
      "Epoch 132/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 0.8774 - accuracy: 0.7086 - val_loss: 11.5976 - val_accuracy: 0.1432\n",
      "Epoch 133/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8818 - accuracy: 0.7026 - val_loss: 10.5736 - val_accuracy: 0.1411\n",
      "Epoch 134/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8660 - accuracy: 0.7048 - val_loss: 11.6440 - val_accuracy: 0.1379\n",
      "Epoch 135/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8550 - accuracy: 0.7155 - val_loss: 11.3995 - val_accuracy: 0.1442\n",
      "Epoch 136/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.8636 - accuracy: 0.7077 - val_loss: 12.0586 - val_accuracy: 0.1437\n",
      "Epoch 137/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8701 - accuracy: 0.7050 - val_loss: 11.6106 - val_accuracy: 0.1505\n",
      "Epoch 138/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.8565 - accuracy: 0.7144 - val_loss: 11.3045 - val_accuracy: 0.1411\n",
      "Epoch 139/200\n",
      "239/239 [==============================] - 5s 20ms/step - loss: 0.8703 - accuracy: 0.7073 - val_loss: 11.5846 - val_accuracy: 0.1479\n",
      "Epoch 140/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8615 - accuracy: 0.7104 - val_loss: 12.1206 - val_accuracy: 0.1474\n",
      "Epoch 141/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8703 - accuracy: 0.7083 - val_loss: 11.0085 - val_accuracy: 0.1463\n",
      "Epoch 142/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8550 - accuracy: 0.7086 - val_loss: 11.9298 - val_accuracy: 0.1442\n",
      "Epoch 143/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8543 - accuracy: 0.7125 - val_loss: 12.0350 - val_accuracy: 0.1458\n",
      "Epoch 144/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8630 - accuracy: 0.7071 - val_loss: 11.4092 - val_accuracy: 0.1369\n",
      "Epoch 145/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8565 - accuracy: 0.7145 - val_loss: 12.2725 - val_accuracy: 0.1505\n",
      "Epoch 146/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8565 - accuracy: 0.7081 - val_loss: 12.1299 - val_accuracy: 0.1432\n",
      "Epoch 147/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8665 - accuracy: 0.7032 - val_loss: 12.2323 - val_accuracy: 0.1458\n",
      "Epoch 148/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8486 - accuracy: 0.7120 - val_loss: 11.9170 - val_accuracy: 0.1479\n",
      "Epoch 149/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8606 - accuracy: 0.7136 - val_loss: 11.7290 - val_accuracy: 0.1463\n",
      "Epoch 150/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8529 - accuracy: 0.7077 - val_loss: 12.4748 - val_accuracy: 0.1442\n",
      "Epoch 151/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8543 - accuracy: 0.7148 - val_loss: 12.1215 - val_accuracy: 0.1416\n",
      "Epoch 152/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8477 - accuracy: 0.7159 - val_loss: 12.3558 - val_accuracy: 0.1405\n",
      "Epoch 153/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8635 - accuracy: 0.7149 - val_loss: 11.7373 - val_accuracy: 0.1494\n",
      "Epoch 154/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8610 - accuracy: 0.7071 - val_loss: 11.9931 - val_accuracy: 0.1411\n",
      "Epoch 155/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 0.8428 - accuracy: 0.7134 - val_loss: 12.0568 - val_accuracy: 0.1384\n",
      "Epoch 156/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8493 - accuracy: 0.7116 - val_loss: 12.0456 - val_accuracy: 0.1411\n",
      "Epoch 157/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8532 - accuracy: 0.7095 - val_loss: 11.7554 - val_accuracy: 0.1442\n",
      "Epoch 158/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8392 - accuracy: 0.7204 - val_loss: 11.9597 - val_accuracy: 0.1316\n",
      "Epoch 159/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8327 - accuracy: 0.7226 - val_loss: 12.2325 - val_accuracy: 0.1479\n",
      "Epoch 160/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8504 - accuracy: 0.7140 - val_loss: 12.6867 - val_accuracy: 0.1390\n",
      "Epoch 161/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8334 - accuracy: 0.7239 - val_loss: 12.4683 - val_accuracy: 0.1411\n",
      "Epoch 162/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8304 - accuracy: 0.7251 - val_loss: 13.1967 - val_accuracy: 0.1453\n",
      "Epoch 163/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8309 - accuracy: 0.7246 - val_loss: 12.5978 - val_accuracy: 0.1390\n",
      "Epoch 164/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8578 - accuracy: 0.7073 - val_loss: 12.5851 - val_accuracy: 0.1442\n",
      "Epoch 165/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.8408 - accuracy: 0.7129 - val_loss: 12.7287 - val_accuracy: 0.1484\n",
      "Epoch 166/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 0.8356 - accuracy: 0.7191 - val_loss: 12.3771 - val_accuracy: 0.1437\n",
      "Epoch 167/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8264 - accuracy: 0.7266 - val_loss: 12.7379 - val_accuracy: 0.1463\n",
      "Epoch 168/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8371 - accuracy: 0.7220 - val_loss: 12.5470 - val_accuracy: 0.1421\n",
      "Epoch 169/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8275 - accuracy: 0.7275 - val_loss: 13.0485 - val_accuracy: 0.1500\n",
      "Epoch 170/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8335 - accuracy: 0.7237 - val_loss: 12.7385 - val_accuracy: 0.1463\n",
      "Epoch 171/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8374 - accuracy: 0.7231 - val_loss: 12.5678 - val_accuracy: 0.1500\n",
      "Epoch 172/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 0.8353 - accuracy: 0.7182 - val_loss: 12.7857 - val_accuracy: 0.1474\n",
      "Epoch 173/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8314 - accuracy: 0.7221 - val_loss: 12.9378 - val_accuracy: 0.1479\n",
      "Epoch 174/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8395 - accuracy: 0.7161 - val_loss: 12.6898 - val_accuracy: 0.1484\n",
      "Epoch 175/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8349 - accuracy: 0.7161 - val_loss: 12.3306 - val_accuracy: 0.1500\n",
      "Epoch 176/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8231 - accuracy: 0.7196 - val_loss: 13.6289 - val_accuracy: 0.1542\n",
      "Epoch 177/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8203 - accuracy: 0.7310 - val_loss: 12.5269 - val_accuracy: 0.1353\n",
      "Epoch 178/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8217 - accuracy: 0.7247 - val_loss: 13.5045 - val_accuracy: 0.1521\n",
      "Epoch 179/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8140 - accuracy: 0.7260 - val_loss: 13.5014 - val_accuracy: 0.1479\n",
      "Epoch 180/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8490 - accuracy: 0.7149 - val_loss: 12.6127 - val_accuracy: 0.1463\n",
      "Epoch 181/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8181 - accuracy: 0.7229 - val_loss: 13.2209 - val_accuracy: 0.1484\n",
      "Epoch 182/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8083 - accuracy: 0.7321 - val_loss: 14.1872 - val_accuracy: 0.1421\n",
      "Epoch 183/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8275 - accuracy: 0.7306 - val_loss: 13.4607 - val_accuracy: 0.1442\n",
      "Epoch 184/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8125 - accuracy: 0.7283 - val_loss: 13.5204 - val_accuracy: 0.1468\n",
      "Epoch 185/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8210 - accuracy: 0.7256 - val_loss: 13.2929 - val_accuracy: 0.1484\n",
      "Epoch 186/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.8071 - accuracy: 0.7353 - val_loss: 13.2633 - val_accuracy: 0.1479\n",
      "Epoch 187/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8248 - accuracy: 0.7287 - val_loss: 12.9723 - val_accuracy: 0.1442\n",
      "Epoch 188/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8108 - accuracy: 0.7373 - val_loss: 13.0742 - val_accuracy: 0.1442\n",
      "Epoch 189/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8095 - accuracy: 0.7314 - val_loss: 13.0300 - val_accuracy: 0.1395\n",
      "Epoch 190/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8061 - accuracy: 0.7327 - val_loss: 13.6003 - val_accuracy: 0.1557\n",
      "Epoch 191/200\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 0.8098 - accuracy: 0.7326 - val_loss: 13.6721 - val_accuracy: 0.1500\n",
      "Epoch 192/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8119 - accuracy: 0.7283 - val_loss: 13.4819 - val_accuracy: 0.1432\n",
      "Epoch 193/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8037 - accuracy: 0.7338 - val_loss: 14.2024 - val_accuracy: 0.1463\n",
      "Epoch 194/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8120 - accuracy: 0.7329 - val_loss: 12.8649 - val_accuracy: 0.1400\n",
      "Epoch 195/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 0.8174 - accuracy: 0.7318 - val_loss: 13.0888 - val_accuracy: 0.1411\n",
      "Epoch 196/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.8104 - accuracy: 0.7304 - val_loss: 13.4646 - val_accuracy: 0.1526\n",
      "Epoch 197/200\n",
      "239/239 [==============================] - 5s 20ms/step - loss: 0.8016 - accuracy: 0.7346 - val_loss: 13.6744 - val_accuracy: 0.1358\n",
      "Epoch 198/200\n",
      "239/239 [==============================] - 4s 19ms/step - loss: 0.8012 - accuracy: 0.7357 - val_loss: 13.4432 - val_accuracy: 0.1573\n",
      "Epoch 199/200\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 0.8178 - accuracy: 0.7277 - val_loss: 13.7226 - val_accuracy: 0.1463\n",
      "Epoch 200/200\n",
      "239/239 [==============================] - 5s 19ms/step - loss: 0.8033 - accuracy: 0.7388 - val_loss: 13.3138 - val_accuracy: 0.1384\n"
     ]
    }
   ],
   "source": [
    "cnn = model.fit(X_train_final, y_train, epochs=200,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-34f3aa404ddd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(cnn.history['loss'], label='loss', marker = 'o')\n",
    "plt.plot(cnn.history['val_loss'], label = 'val_loss', marker = 'o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_nonfic = ['Fiction', 'Nonfiction']\n",
    "df_binary = df.loc[df['genres'].isin(fic_nonfic)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = df_binary[\"book_desc\"]\n",
    "y_binary = df_binary[\"genres\"]\n",
    "\n",
    "\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_binary, y_binary,  test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train_binary))\n",
    "#Transforms each text in texts to a sequence of integers.\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(X_train_binary)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(X_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default batch size 32\n",
    "#Optional Int, maximum length of all sequences. \n",
    "#If not provided, sequences will be padded to the length of the longest individual sequence.\n",
    "maxlen = 100 \n",
    "embed_size = 64 \n",
    "#Pads sequences to the same length.\n",
    "X_train_final = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_test_final = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen, )) \n",
    "x   =  Embedding(max_features, embed_size)(input)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(10, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"softmax\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.02))(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input, outputs=x)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "239/239 [==============================] - 6s 19ms/step - loss: 3.1512 - accuracy: 0.1643 - val_loss: 2.4021 - val_accuracy: 0.1951\n",
      "Epoch 2/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.3784 - accuracy: 0.1818 - val_loss: 2.2974 - val_accuracy: 0.1951\n",
      "Epoch 3/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.2969 - accuracy: 0.1843 - val_loss: 2.2552 - val_accuracy: 0.1867\n",
      "Epoch 4/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.2592 - accuracy: 0.1852 - val_loss: 2.2441 - val_accuracy: 0.1578\n",
      "Epoch 5/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.2203 - accuracy: 0.1789 - val_loss: 2.2287 - val_accuracy: 0.1867\n",
      "Epoch 6/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.1913 - accuracy: 0.1889 - val_loss: 2.2275 - val_accuracy: 0.1578\n",
      "Epoch 7/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.1650 - accuracy: 0.1843 - val_loss: 2.2228 - val_accuracy: 0.1867\n",
      "Epoch 8/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.1383 - accuracy: 0.1870 - val_loss: 2.2399 - val_accuracy: 0.1867\n",
      "Epoch 9/20\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 2.1137 - accuracy: 0.1812 - val_loss: 2.2392 - val_accuracy: 0.1867\n",
      "Epoch 10/20\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 2.0823 - accuracy: 0.1873 - val_loss: 2.2573 - val_accuracy: 0.1924\n",
      "Epoch 11/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 2.0543 - accuracy: 0.1862 - val_loss: 2.2997 - val_accuracy: 0.1966\n",
      "Epoch 12/20\n",
      "239/239 [==============================] - 5s 20ms/step - loss: 2.0212 - accuracy: 0.1868 - val_loss: 2.3186 - val_accuracy: 0.1814\n",
      "Epoch 13/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.9884 - accuracy: 0.1925 - val_loss: 2.3587 - val_accuracy: 0.1542\n",
      "Epoch 14/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.9537 - accuracy: 0.1925 - val_loss: 2.4252 - val_accuracy: 0.1835\n",
      "Epoch 15/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.9255 - accuracy: 0.2014 - val_loss: 2.4972 - val_accuracy: 0.1767\n",
      "Epoch 16/20\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.9025 - accuracy: 0.2151 - val_loss: 2.5382 - val_accuracy: 0.1757\n",
      "Epoch 17/20\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.8852 - accuracy: 0.2271 - val_loss: 2.5473 - val_accuracy: 0.1594\n",
      "Epoch 18/20\n",
      "239/239 [==============================] - 4s 17ms/step - loss: 1.8678 - accuracy: 0.2383 - val_loss: 2.7021 - val_accuracy: 0.1757\n",
      "Epoch 19/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.8593 - accuracy: 0.2573 - val_loss: 2.6889 - val_accuracy: 0.1599\n",
      "Epoch 20/20\n",
      "239/239 [==============================] - 4s 18ms/step - loss: 1.8452 - accuracy: 0.2683 - val_loss: 2.6631 - val_accuracy: 0.1447\n"
     ]
    }
   ],
   "source": [
    "cnn_binary = model.fit(X_train_final, y_train, epochs=20,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2192eac3250>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnn_binary.history['loss'], label='loss', marker = 'o')\n",
    "plt.plot(cnn_binary.history['val_loss'], label = 'val_loss', marker = 'o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

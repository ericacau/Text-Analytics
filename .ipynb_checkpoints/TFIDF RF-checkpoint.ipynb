{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing & visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models for classification\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(pipeline, X_test, y_test):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plot_confusion_matrix(pipeline, X_test, y_test)  \n",
    "    plt.xticks(rotation=45, fontsize = 10)\n",
    "    plt.yticks(rotation=0, fontsize = 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/books_def.csv\", index_col=0)\n",
    "fic_nonfic = ['Fiction', 'Nonfiction']\n",
    "df_binary = df.loc[df['genres'].isin(fic_nonfic)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggo testi & etichette\n",
    "X = df[\"book_desc\"]\n",
    "y = df[\"genres\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickle/svm_train_tok.pkl',mode='br') as inputfile:\n",
    "    X_train_tok = pickle.load(inputfile)\n",
    "with open('data/pickle/svm_test_tok.pkl',mode='br') as inputfile:\n",
    "    X_test_tok = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.78      0.12      0.21       477\n",
      "        Fantasy       0.55      0.70      0.61      1891\n",
      "        Fiction       0.42      0.64      0.51      2134\n",
      "     Historical       0.81      0.03      0.06       643\n",
      "        Mystery       0.69      0.29      0.41       612\n",
      "     Nonfiction       0.65      0.87      0.74      1951\n",
      "        Romance       0.56      0.68      0.62      1362\n",
      "Science Fiction       0.73      0.23      0.35       525\n",
      " Sequential Art       0.95      0.15      0.26       399\n",
      "    Young Adult       0.56      0.26      0.36       998\n",
      "\n",
      "       accuracy                           0.55     10992\n",
      "      macro avg       0.67      0.40      0.41     10992\n",
      "   weighted avg       0.60      0.55      0.51     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[  58   26  210    0    6  166    5    2    0    4]\n",
      " [   3 1325  248    0   12  107  136    9    2   49]\n",
      " [   7  218 1368    4   19  301  162   11    0   44]\n",
      " [   0  102  338   21    5   78   79    2    0   18]\n",
      " [   0  105  201    0  177   31   75    1    0   22]\n",
      " [   5   24  188    0    1 1702   22    2    0    7]\n",
      " [   1  142  189    0   15   45  928    1    0   41]\n",
      " [   0  142  138    0    7   72   39  119    1    7]\n",
      " [   0   85  129    1    7   76   14   10   59   18]\n",
      " [   0  261  227    0    6   53  183    5    0  263]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=5000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = RF_pipeline.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=5)]: Done  90 out of  90 | elapsed: 57.0min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'sel__k': [3000, 5000, 7000],'learner__criterion': [\"entropy\", \"gini\"], 'learner__n_estimators': [100, 300, 500]}]\n",
    "\n",
    "opt_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier(bootstrap = True))  # learning algorithm\n",
    "])\n",
    "\n",
    "n_jobs = 5  #Number of jobs to run in parallel\n",
    "opt_search = GridSearchCV(opt_pipeline, param_grid, cv=5, n_jobs = n_jobs, verbose=True).fit(X_train_tok,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner__criterion': 'gini', 'learner__n_estimators': 500, 'sel__k': 3000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sel',\n",
       "                 SelectKBest(k=3000,\n",
       "                             score_func=<function chi2 at 0x0000025242C22EE0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('learner', RandomForestClassifier(n_estimators=500))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.80      0.12      0.20       477\n",
      "        Fantasy       0.56      0.71      0.62      1891\n",
      "        Fiction       0.44      0.66      0.53      2134\n",
      "     Historical       0.88      0.03      0.06       643\n",
      "        Mystery       0.73      0.31      0.44       612\n",
      "     Nonfiction       0.65      0.88      0.75      1951\n",
      "        Romance       0.58      0.70      0.64      1362\n",
      "Science Fiction       0.74      0.26      0.39       525\n",
      " Sequential Art       0.91      0.15      0.26       399\n",
      "    Young Adult       0.59      0.28      0.38       998\n",
      "\n",
      "       accuracy                           0.56     10992\n",
      "      macro avg       0.69      0.41      0.43     10992\n",
      "   weighted avg       0.62      0.56      0.52     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[  55   23  215    0    4  170    6    1    0    3]\n",
      " [   2 1337  231    0   11  110  145    9    4   42]\n",
      " [   6  204 1415    2   18  291  142   15    0   41]\n",
      " [   1  111  326   21    6   86   72    2    0   18]\n",
      " [   0  102  194    0  190   36   64    0    1   25]\n",
      " [   5   21  178    0    0 1721   19    3    0    4]\n",
      " [   0  125  179    1   12   47  959    2    0   37]\n",
      " [   0  137  140    0    6   54   38  137    1   12]\n",
      " [   0   89  122    0    7   79   15   12   61   14]\n",
      " [   0  239  228    0    6   53  191    3    0  278]]\n"
     ]
    }
   ],
   "source": [
    "opt_predictions = opt_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, opt_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Classics       0.79      0.11      0.19       477\n",
      "        Fantasy       0.55      0.72      0.63      1891\n",
      "        Fiction       0.43      0.66      0.52      2134\n",
      "     Historical       0.94      0.03      0.05       643\n",
      "        Mystery       0.74      0.29      0.41       612\n",
      "     Nonfiction       0.66      0.89      0.76      1951\n",
      "        Romance       0.59      0.70      0.64      1362\n",
      "Science Fiction       0.78      0.22      0.34       525\n",
      " Sequential Art       0.60      0.13      0.22       399\n",
      "    Young Adult       0.61      0.26      0.37       998\n",
      "\n",
      "       accuracy                           0.56     10992\n",
      "      macro avg       0.67      0.40      0.41     10992\n",
      "   weighted avg       0.61      0.56      0.52     10992\n",
      "\n",
      "Confusion matrix:\n",
      "[[  53   28  218    0    3  162    7    1    2    3]\n",
      " [   2 1367  228    0   11  103  131    6    9   34]\n",
      " [   7  188 1413    1   18  299  146    9    5   48]\n",
      " [   0  116  354   17    4   74   61    2    1   14]\n",
      " [   1   95  224    0  175   29   69    0    4   15]\n",
      " [   3   17  165    0    0 1731   23    2    7    3]\n",
      " [   1  145  185    0   10   33  958    2    2   26]\n",
      " [   0  153  140    0    6   58   42  115    3    8]\n",
      " [   0  103  122    0    6   77   13    9   53   16]\n",
      " [   0  258  240    0    5   49  179    1    2  264]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2, k=7000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier(n_estimators=500, criterion = \"gini\"))  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_tok,y_train)\n",
    "predictions = RF_pipeline.predict(X_test_tok)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ca003f3464d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "plot_cm(dt_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = df_binary[\"book_desc\"]\n",
    "y_binary = df_binary[\"genres\"]\n",
    "\n",
    "\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_binary, y_binary,  test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect= TfidfVectorizer(max_df=0.8, max_features=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "transform\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('fit')\n",
    "# Just creating the features space. It define the dimensions.\n",
    "vect.fit(X_train_binary) \n",
    "print('transform')\n",
    "#Creating the vectors\n",
    "X_train_tok_binary = vect.transform(X_train_binary)\n",
    "print('done')\n",
    "X_test_tok_binary = vect.transform(X_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fiction       1.00      1.00      1.00      4990\n",
      "  Nonfiction       1.00      1.00      1.00      4542\n",
      "\n",
      "    accuracy                           1.00      9532\n",
      "   macro avg       1.00      1.00      1.00      9532\n",
      "weighted avg       1.00      1.00      1.00      9532\n",
      "\n",
      "Confusion matrix:\n",
      "[[4987    3]\n",
      " [   1 4541]]\n"
     ]
    }
   ],
   "source": [
    "RF_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df = 5)), #tokenization\n",
    "    ('sel', SelectKBest(chi2, k=7000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', RandomForestClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "RF_pipeline.fit(X_train_binary, y_train_binary)\n",
    "predictions_test_binary = RF_pipeline.predict(X_test_binary)\n",
    "predictions_train_binary = RF_pipeline.predict(X_train_binary)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_train_binary, predictions_train_binary))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_train_binary, predictions_train_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fiction       0.85      0.92      0.89      2124\n",
      "  Nonfiction       0.91      0.83      0.87      1962\n",
      "\n",
      "    accuracy                           0.88      4086\n",
      "   macro avg       0.88      0.88      0.88      4086\n",
      "weighted avg       0.88      0.88      0.88      4086\n",
      "\n",
      "Confusion matrix:\n",
      "[[1960  164]\n",
      " [ 337 1625]]\n"
     ]
    }
   ],
   "source": [
    "predictions_test_binary = RF_pipeline.predict(X_test_binary)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test_binary, predictions_test_binary))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test_binary, predictions_test_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
